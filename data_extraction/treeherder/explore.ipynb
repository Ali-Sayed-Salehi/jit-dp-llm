{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xkAzrcKPxXa"
      },
      "source": [
        "# Mozilla Treeherder API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxSVXXjS3rKi"
      },
      "source": [
        "Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5dU_EU43tKq"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pprint import pprint\n",
        "import datetime\n",
        "from thclient import TreeherderClient\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import time\n",
        "import ast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1l0M3ynbXaq"
      },
      "source": [
        "Initialize the Treeherder Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaQCG8b0bYHi"
      },
      "outputs": [],
      "source": [
        "client = TreeherderClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaZHkwGJ30Ti"
      },
      "source": [
        "Get a single job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VTdtmdHdvQUL",
        "outputId": "d434fa89-5c94-4273-87a0-c77994a65f7d"
      },
      "outputs": [],
      "source": [
        "job_params = {\n",
        "    \"id\":492088703\n",
        "}\n",
        "\n",
        "client.get_jobs(\"mozilla-central\", **job_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whwpqHdc32gb"
      },
      "source": [
        "Get performance summaries for a specific period and specific infrastructure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8B3Q6i2_xGDl",
        "outputId": "47228959-1c1b-411a-81fd-940fa6b9bee1"
      },
      "outputs": [],
      "source": [
        "performance_summary_params = {\n",
        "    \"repository\": \"mozilla-central\",\n",
        "    \"signature\":308858,\n",
        "    \"interval\":2592000,\n",
        "    \"all_data\":True,\n",
        "    \"replicates\":False\n",
        "}\n",
        "\n",
        "data_list = client._get_json(\"performance/summary\", **performance_summary_params)\n",
        "data_dict = data_list[0]\n",
        "for key in data_dict:\n",
        "    print(key, \" -> \", data_dict[key])\n",
        "    if key == \"data\":\n",
        "        jobs_list = data_dict[key]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9YsYeA26YJC"
      },
      "source": [
        "Get all performance test frameworks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0jmj2Vst6aNh",
        "outputId": "9f399084-78b3-497b-b23d-04aa86359a2b"
      },
      "outputs": [],
      "source": [
        "client._get_json(\"performance/framework\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSElx6Aj5hgu"
      },
      "source": [
        "Get performance test framework by id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evl1npOd5j1d",
        "outputId": "a5d6a0ce-667c-4e96-a200-03e8d4412cf0"
      },
      "outputs": [],
      "source": [
        "performance_framework_id = 1\n",
        "performance_framework_endpoint = f\"performance/framework/{performance_framework_id}\"\n",
        "\n",
        "client._get_json(performance_framework_endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkYyWL8U7SVW"
      },
      "source": [
        "Get all repositories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k4794OWp7T50",
        "outputId": "68d5e62b-c417-49c0-b527-d57355a225a1"
      },
      "outputs": [],
      "source": [
        "repos_list = client._get_json(\"repository\")\n",
        "for repo in repos_list:\n",
        "  print(repo['name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbod5jIc8BOW"
      },
      "source": [
        "Get all machine platforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GaYE-TJ08Avf",
        "outputId": "389cd144-aa5b-4e67-b37d-76ea225e44f1"
      },
      "outputs": [],
      "source": [
        "client._get_json(\"machineplatforms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEztY0IX8cYv"
      },
      "source": [
        "Get all machine platforms for a particular branch/project that has performance test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eRbP2Lbn8c5A",
        "outputId": "543c09ae-0fb3-4316-9f9d-86751f890945"
      },
      "outputs": [],
      "source": [
        "client._get_json(\"performance/platforms\", \"autoland\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_foM_B31alRi"
      },
      "source": [
        "Get performance test signatures for a given project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zHw2ZU7ap4L",
        "outputId": "5210df7b-48d2-4155-ef3c-7bc816ea97c9"
      },
      "outputs": [],
      "source": [
        "signature_summary_params = {\n",
        "    # \"framework\":1,\n",
        "    # \"platform\":\"linux1804-64-shippable-qr\",\n",
        "    # \"id\": 308858 # mozilla central\n",
        "    # \"id\": 307933 # same test for autoland\n",
        "}\n",
        "\n",
        "data_dict = client._get_json(\"performance/signatures\", \"autoland\", **signature_summary_params)\n",
        "for key in data_dict:\n",
        "    print(key, \" -> \", data_dict[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UhJByreLKam"
      },
      "source": [
        "Get all the jobs/performance test times for a certain signature for the last 30 days for mozilla central"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5wtYTWigLLGS",
        "outputId": "41369ac9-e0fa-4fe6-a75e-2876529ef0e2"
      },
      "outputs": [],
      "source": [
        "performance_summary_params = {\n",
        "    \"repository\": \"mozilla-central\",\n",
        "    \"signature\":308858,\n",
        "    \"interval\":2592000,\n",
        "    \"all_data\":True,\n",
        "    \"replicates\":False\n",
        "}\n",
        "\n",
        "data_list = client._get_json(\"performance/summary\", **performance_summary_params)\n",
        "data_dict = data_list[0]\n",
        "jobs_list = data_dict['data']\n",
        "for index, job in enumerate(jobs_list):\n",
        "  job_params = {\n",
        "      \"id\":job[\"job_id\"]\n",
        "  }\n",
        "  single_job_list = client.get_jobs(\"mozilla-central\", **job_params)\n",
        "  job_dict = single_job_list[0]\n",
        "  submit_time = datetime.fromtimestamp(job_dict['submit_timestamp'])\n",
        "  start_time = datetime.fromtimestamp(job_dict['start_timestamp'])\n",
        "  end_time = datetime.fromtimestamp(job_dict['end_timestamp'])\n",
        "  duration = end_time - start_time\n",
        "  wait_time = end_time - submit_time\n",
        "\n",
        "  if index == 0:\n",
        "    prev_submit_time = submit_time\n",
        "\n",
        "  submit_time_diff = submit_time - prev_submit_time\n",
        "  prev_submit_time = submit_time\n",
        "\n",
        "\n",
        "  print(\"id: \", job_dict['id'],\n",
        "        \" -> \",\n",
        "        \"   submit time: \", submit_time,\n",
        "        \"   start time: \", start_time,\n",
        "        \"   end time: \", end_time,\n",
        "        \"   duration: \", duration,\n",
        "        \"   wait time: \", wait_time,\n",
        "        \"   submit time difference: \", submit_time_diff)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r56x9l_D-ZZV"
      },
      "source": [
        "Get all the jobs/performance test times for a certain signature for the last 30 days for autoland"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NXNxmwk9-bKY",
        "outputId": "2e823d32-f3e8-4ef7-c604-d9abffd1cabc"
      },
      "outputs": [],
      "source": [
        "performance_summary_params = {\n",
        "    \"repository\": \"autoland\",\n",
        "    \"signature\":307933,\n",
        "    \"interval\":2592000,\n",
        "    \"all_data\":True,\n",
        "    \"replicates\":False\n",
        "}\n",
        "\n",
        "data_list = client._get_json(\"performance/summary\", **performance_summary_params)\n",
        "data_dict = data_list[0]\n",
        "jobs_list = data_dict['data']\n",
        "for index, job in enumerate(jobs_list):\n",
        "  job_params = {\n",
        "      \"id\":job[\"job_id\"]\n",
        "  }\n",
        "  single_job_list = client.get_jobs(\"autoland\", **job_params)\n",
        "  job_dict = single_job_list[0]\n",
        "  submit_time = datetime.fromtimestamp(job_dict['submit_timestamp'])\n",
        "  start_time = datetime.fromtimestamp(job_dict['start_timestamp'])\n",
        "  end_time = datetime.fromtimestamp(job_dict['end_timestamp'])\n",
        "  duration = end_time - start_time\n",
        "  wait_time = end_time - submit_time\n",
        "\n",
        "  if index == 0:\n",
        "    prev_submit_time = submit_time\n",
        "\n",
        "  submit_time_diff = submit_time - prev_submit_time\n",
        "  prev_submit_time = submit_time\n",
        "\n",
        "\n",
        "  print(\"id: \", job_dict['id'],\n",
        "        \" -> \",\n",
        "        \"   submit time: \", submit_time,\n",
        "        \"   start time: \", start_time,\n",
        "        \"   end time: \", end_time,\n",
        "        \"   duration: \", duration,\n",
        "        \"   wait time: \", wait_time,\n",
        "        \"   submit time difference: \", submit_time_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get all performance alerts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client._get_json(\"performance/alert\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract all the alert summaries for a specific siganture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alert_summary_params = {\n",
        "    \"alerts__series_signature\": 5095204, # autoland\n",
        "    \"timerange\": 31536000 # last year\n",
        "}\n",
        "\n",
        "client._get_json(\"performance/alertsummary\", **alert_summary_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract all the alert summaries for a specific siganture.\n",
        "Extract all the performance summaries, i.e. performance tests/jobs for a specific signature.\n",
        "Merge the two data frames on push_id so that we can determine if a test has lead to a performance alert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### Creating jobs' dataframe\n",
        "\n",
        "performance_summary_params = {\n",
        "    \"repository\": \"autoland\",\n",
        "    \"signature\":5095204,\n",
        "    \"interval\":31536000,\n",
        "    \"all_data\":True,\n",
        "    \"replicates\":False\n",
        "}\n",
        "\n",
        "performance_summaries_list = client._get_json(\"performance/summary\", **performance_summary_params)\n",
        "performance_summaries_dict = performance_summaries_list[0]\n",
        "jobs_list = performance_summaries_dict['data']\n",
        "\n",
        "job_push_ids_list = []\n",
        "job_ids_list = []\n",
        "\n",
        "for index, job in enumerate(jobs_list):\n",
        "  if job[\"job_id\"]:\n",
        "    job_push_ids_list.append(job[\"push_id\"])\n",
        "    job_ids_list.append(job[\"job_id\"])\n",
        "\n",
        "jobs_df = pd.DataFrame({'job_id': job_ids_list, 'job_push_id': job_push_ids_list})\n",
        "\n",
        "### Creating alerts' dataframe\n",
        "\n",
        "alert_summary_params = {\n",
        "    \"alerts__series_signature\": 5095204, # autoland\n",
        "    \"timerange\": 31536000 # last year\n",
        "}\n",
        "\n",
        "alert_summaries_response_dict = client._get_json(\"performance/alertsummary\", **alert_summary_params)\n",
        "alert_summaries_list = alert_summaries_response_dict[\"results\"]\n",
        "\n",
        "alert_ids_list = []\n",
        "alert_push_ids_list = []\n",
        "alert_bug_ids_list = []\n",
        "\n",
        "for alert_summary in alert_summaries_list:\n",
        "  for alert in alert_summary[\"alerts\"]:    \n",
        "    alert_ids_list.append(alert[\"id\"])\n",
        "    alert_push_ids_list.append(alert_summary[\"push_id\"])\n",
        "    alert_bug_ids_list.append(alert_summary.get(\"bug_number\"))\n",
        "    \n",
        "\n",
        "bug_ids_list_without_none = [id for id in alert_bug_ids_list if id is not None]\n",
        "\n",
        "alerts_df = pd.DataFrame({'alert_id': alert_ids_list, 'alert_push_id': alert_push_ids_list, 'alert_bug_id': alert_bug_ids_list})\n",
        "\n",
        "pprint(alerts_df)\n",
        "pprint(bug_ids_list_without_none)\n",
        "    \n",
        "# Merge on alert_push_id and job_push_id\n",
        "jobs_perf_regression_info_df = pd.merge(jobs_df, alerts_df, left_on='job_push_id', right_on='alert_push_id', how='left')\n",
        "\n",
        "# Drop duplicate job_push_id column\n",
        "jobs_perf_regression_info_df.drop(columns=['alert_push_id'], inplace=True)\n",
        "\n",
        "pprint(jobs_perf_regression_info_df)\n",
        "\n",
        "\n",
        "for index, row in jobs_perf_regression_info_df.iterrows():\n",
        "  job_params = {\n",
        "      \"id\":row[\"job_id\"].astype(int)\n",
        "  }\n",
        "\n",
        "  single_job_list = client.get_jobs(\"autoland\", **job_params)\n",
        "\n",
        "  job_dict = single_job_list[0]\n",
        "  submit_time = datetime.fromtimestamp(job_dict['submit_timestamp'])\n",
        "  start_time = datetime.fromtimestamp(job_dict['start_timestamp'])\n",
        "  end_time = datetime.fromtimestamp(job_dict['end_timestamp'])\n",
        "  duration = end_time - start_time\n",
        "  wait_time = end_time - submit_time\n",
        "\n",
        "  if index == 0:\n",
        "    prev_submit_time = submit_time\n",
        "\n",
        "  submit_time_diff = submit_time - prev_submit_time\n",
        "  prev_submit_time = submit_time\n",
        "\n",
        "\n",
        "  print(\"id: \", job_dict['id'],\n",
        "        \" -> \",\n",
        "        \"   submit time: \", submit_time,\n",
        "        \"   wait time: \", wait_time,\n",
        "        \"   alert id: \", row['alert_id'],\n",
        "        \"   perf bug id: \", row['alert_bug_id'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Categorize alerts based on their status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alert_summary_params = {\n",
        "    \"alerts__series_signature\": 5095204, # autoland\n",
        "    \"timerange\": 31536000 # last year\n",
        "}\n",
        "\n",
        "alert_summary_status_dict = {\n",
        "  0: \"untriaged\",\n",
        "  1: \"downstream\",\n",
        "  2: \"reassigned\",\n",
        "  3: \"invalid\",\n",
        "  4: \"improvement\",\n",
        "  5: \"investigating\",\n",
        "  6: \"wontfix\",\n",
        "  7: \"fixed\",\n",
        "  8: \"backedout\"\n",
        "}\n",
        "\n",
        "alert_status_dict = {\n",
        "  0: \"untriaged\",\n",
        "  1: \"downstream\",\n",
        "  2: \"reassigned\",\n",
        "  3: \"invalid\",\n",
        "  4: \"acknowledged\"\n",
        "}\n",
        "\n",
        "alert_summaries_response_dict = client._get_json(\"performance/alertsummary\", **alert_summary_params)\n",
        "alert_summaries_list = alert_summaries_response_dict[\"results\"]\n",
        "\n",
        "alert_ids_list = []\n",
        "alert_status_list = []\n",
        "\n",
        "for alert_summary in alert_summaries_list:\n",
        "  for alert in alert_summary[\"alerts\"]:    \n",
        "    alert_ids_list.append(alert[\"id\"])\n",
        "\n",
        "    alert_status_number = alert[\"status\"]\n",
        "    alert_status = alert_status_dict[alert_status_number]\n",
        "\n",
        "    alert_status_number_from_summary = alert_summary[\"status\"]\n",
        "    alert_status_from_summary = alert_summary_status_dict[alert_status_number_from_summary]\n",
        "\n",
        "    alert_status_list.append(alert_status_dict[alert_status_number])\n",
        "\n",
        "status_counts = Counter(alert_status_list)\n",
        "\n",
        "pprint(status_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Get all the perf alert summaries for the last year\n",
        "- For each alert summary, get the perf tests that detected a regression\n",
        "- remove alerts summaries that are not regressions or are invalid\n",
        "- Get all the bugs from relevant alert summaries\n",
        "- make a csv file from these bugs and name it regressions.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TIMESPAN_IN_DAYS = 365\n",
        "COLUMNS = [\"regression bug id\"]\n",
        "\n",
        "ALERT_SUMMARY_STATUS_DICT = {\n",
        "  \"untriaged\": 0,\n",
        "  \"downstream\": 1,\n",
        "  \"reassigned\": 2,\n",
        "  \"invalid\": 3,\n",
        "  \"improvement\": 4,\n",
        "  \"investigating\": 5,\n",
        "  \"wontfix\": 6,\n",
        "  \"fixed\": 7,\n",
        "  \"backedout\": 8\n",
        "}\n",
        "\n",
        "INCLUDED_ALERT_SUMMARY_STATUSES = {\n",
        "    ALERT_SUMMARY_STATUS_DICT['wontfix'],\n",
        "    ALERT_SUMMARY_STATUS_DICT['fixed'],\n",
        "    ALERT_SUMMARY_STATUS_DICT['backedout']\n",
        "}\n",
        "\n",
        "alert_summary_params = {\n",
        "    \"page\": 1\n",
        "}\n",
        "\n",
        "now = datetime.now()\n",
        "threshold_time = now - relativedelta(days=TIMESPAN_IN_DAYS)\n",
        "\n",
        "alert_push_time = now\n",
        "uri = \"performance/alertsummary\"\n",
        "\n",
        "alert_summaries_list = []\n",
        "\n",
        "# get alert summaries\n",
        "while (alert_push_time >= threshold_time):\n",
        "\n",
        "    alert_summaries_response_dict = client._get_json(uri, **alert_summary_params)\n",
        "    alert_summaries_list.extend(alert_summaries_response_dict[\"results\"])\n",
        "\n",
        "    next_url = alert_summaries_response_dict['next']\n",
        "    next_page = next_url.split('page=')[1]\n",
        "    alert_summary_params['page'] = next_page\n",
        "\n",
        "    alert_push_time_epoch = alert_summaries_response_dict['results'][-1]['push_timestamp']\n",
        "    alert_push_time = datetime.fromtimestamp(alert_push_time_epoch)\n",
        "\n",
        "    time.sleep(0.5)\n",
        "\n",
        "# print(\"alert summaries:\\n\")\n",
        "# pprint(alert_summaries_list)\n",
        "# print(\"\\n\")\n",
        "\n",
        "alert_summaries_df = pd.DataFrame(alert_summaries_list)\n",
        "alert_summaries_df.to_csv(\"../datasets/alert_summaries.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alert_summaries_df = pd.read_csv(\"../datasets/alert_summaries.csv\")\n",
        "\n",
        "alert_summaries_df['alerts'] = alert_summaries_df['alerts'].apply(ast.literal_eval)\n",
        "alert_summaries_df['related_alerts'] = alert_summaries_df['related_alerts'].apply(ast.literal_eval)\n",
        "alert_summaries_df['bug_number'] = alert_summaries_df['bug_number'].astype('Int64')\n",
        "\n",
        "alert_summaries_list = alert_summaries_df.to_dict(orient='records')\n",
        "\n",
        "filtered_alert_summaries_list = []\n",
        "\n",
        "# filter alert summaries to only include regressions    \n",
        "for alert_summary in alert_summaries_list:\n",
        "    if alert_summary['status'] not in INCLUDED_ALERT_SUMMARY_STATUSES:\n",
        "            continue\n",
        "\n",
        "    filtered_alert_summaries_list.append(alert_summary)\n",
        "\n",
        "# print(\"filtered_alert_summaries_list:\\n\")\n",
        "# pprint(filtered_alert_summaries_list)\n",
        "# print(\"\\n\")\n",
        "\n",
        "# add relevant perf tests to alert summaries\n",
        "alert_summaries_with_added_info_list = []\n",
        "\n",
        "for alert_summary in filtered_alert_summaries_list:\n",
        "            \n",
        "    single_alerts_list = []\n",
        "    regression_tests_set = set()\n",
        "\n",
        "    single_alerts_list.extend(alert_summary['alerts'])\n",
        "    single_alerts_list.extend(alert_summary['related_alerts'])\n",
        "\n",
        "    for alert in single_alerts_list:\n",
        "\n",
        "        if not alert.get('is_regression'):\n",
        "             continue\n",
        "        \n",
        "        alert_test_suite = alert['series_signature'].get('suite')\n",
        "        alert_single_test = alert['series_signature'].get('test')\n",
        "\n",
        "        if alert_test_suite:\n",
        "             regression_tests_set.add(alert_test_suite)\n",
        "\n",
        "        if alert_single_test:\n",
        "             regression_tests_set.add(alert_single_test)\n",
        "\n",
        "\n",
        "    alert_summary['tests_list'] = list(regression_tests_set)\n",
        "\n",
        "    alert_summaries_with_added_info_list.append(alert_summary)\n",
        "\n",
        "# print(\"alert_summaries_with_added_info_list:\\n\")\n",
        "# pprint(alert_summaries_with_added_info_list)\n",
        "# print(\"\\n\")\n",
        "\n",
        "\n",
        "# extract needed columns \n",
        "regression_bug_ids_list = []\n",
        "alert_summary_ids_list = []\n",
        "regression_tests_list = []\n",
        "\n",
        "for alert_summary in alert_summaries_with_added_info_list:\n",
        "     regression_bug_id = alert_summary.get('bug_number')\n",
        "     if regression_bug_id:\n",
        "          regression_bug_ids_list.append(regression_bug_id)\n",
        "          alert_summary_ids_list.append(alert_summary.get(\"id\"))\n",
        "          regression_tests_list.append(alert_summary.get(\"tests_list\"))\n",
        "          \n",
        "# print(\"regression_bug_ids_list:\\n\")\n",
        "# pprint(regression_bug_ids_list)\n",
        "# print(\"\\n\")\n",
        "\n",
        "regressions_df = pd.DataFrame({'regression_bug_id': regression_bug_ids_list, \n",
        "                               'reg_perf_tests_list': regression_tests_list,\n",
        "                               'perf_reg_alert_summary_id': alert_summary_ids_list})\n",
        "\n",
        "regressions_df.to_csv('../datasets/regressions.csv', index=False)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xkPla8f7PiQE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
