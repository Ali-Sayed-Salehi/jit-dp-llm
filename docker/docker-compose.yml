services:
  llama-train-environment:
    build:
      context: ..                 # build context = repo root
      dockerfile: docker/Dockerfile.train
    image: llama-train-environment:latest
    working_dir: /workspace
    user: "${UID:-1000}:${GID:-1000}"
    volumes:
      - ./:/workspace
    command: bash -lc "./download_model.sh"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
