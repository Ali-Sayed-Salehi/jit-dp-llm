{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !huggingface-cli login\n",
    "# !huggingface-cli download meta-llama/Meta-Llama-3-8B --local-dir ../LLMs/pretrained/llama3-8b --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/speed-scratch/a_s87063/repos/perf-pilot/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/speed-scratch/a_s87063/repos/perf-pilot/venv/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login as huggingface_hub_login\n",
    "from datasets import load_dataset, DatasetDict, concatenate_datasets\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig, AutoConfig, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU memory preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log into Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=\"../secrets/.env\")\n",
    "\n",
    "hugging_face_token = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "\n",
    "huggingface_hub_login(hugging_face_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.18s/it]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at ../LLMs/pretrained/llama3-8b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"../LLMs/pretrained/llama3-8b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=True)\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH, num_labels=2)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    config=config,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 8/8 [00:01<00:00,  5.10ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 2/2 [00:00<00:00,  3.66ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! 7444 training / 1862 evaluation samples.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"../datasets/dataset.jsonl\", split=\"train\")\n",
    "\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(dataset) * split_ratio)\n",
    "\n",
    "train_dataset = dataset.select(range(0, split_index))\n",
    "eval_dataset = dataset.select(range(split_index, len(dataset)))\n",
    "\n",
    "# Shuffle ONLY the training set\n",
    "train_dataset = train_dataset.shuffle(seed=42)\n",
    "\n",
    "train_dataset.to_json(\"../datasets/train.jsonl\", orient=\"records\", lines=True)\n",
    "eval_dataset.to_json(\"../datasets/eval.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "print(f\"✅ Done! {len(train_dataset)} training / {len(eval_dataset)} evaluation samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format datasets for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_classification(example):\n",
    "    return {\n",
    "        \"text\": example['prompt'],\n",
    "        \"label\": int(example[\"response\"])\n",
    "    }\n",
    "\n",
    "train_formatted_dataset = train_dataset.map(format_for_classification)\n",
    "eval_formatted_dataset = eval_dataset.map(format_for_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsample the minority class to address class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 7345, 1: 1469})\n"
     ]
    }
   ],
   "source": [
    "majority_class = train_formatted_dataset.filter(lambda example: example['label'] == 0)\n",
    "minority_class = train_formatted_dataset.filter(lambda example: example['label'] == 1)\n",
    "\n",
    "n_majority = len(majority_class)\n",
    "n_minority = len(minority_class)\n",
    "\n",
    "RESAMPLING_SIZE = 5     # creates 1 to 5 class imbalance\n",
    "minority_upsampled_size = int(n_majority / RESAMPLING_SIZE)\n",
    "\n",
    "minority_upsampled = minority_class.shuffle(seed=42).select(\n",
    "    [random.randint(0, n_minority - 1) for _ in range(minority_upsampled_size)]\n",
    ")\n",
    "\n",
    "balanced_dataset = concatenate_datasets([majority_class, minority_upsampled])\n",
    "\n",
    "train_balanced_formatted_dataset = balanced_dataset.shuffle(seed=42)\n",
    "\n",
    "print(Counter(balanced_dataset['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8814/8814 [01:45<00:00, 83.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_class(example):\n",
    "    encoding = tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    encoding[\"labels\"] = example[\"label\"]\n",
    "    return encoding\n",
    "\n",
    "train_tokenized_dataset = train_balanced_formatted_dataset.map(tokenize_class, batched=True)\n",
    "eval_tokenized_dataset = eval_formatted_dataset.map(tokenize_class, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sneak peek into the resulting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(train_balanced_formatted_dataset[0])\n",
    "# pprint(train_balanced_formatted_dataset.column_names)\n",
    "\n",
    "# label_counts = Counter(train_formatted_dataset['label'])\n",
    "# print(label_counts)\n",
    "# 99/7345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply LoRA with PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13,639,680 || all params: 7,518,572,544 || trainable%: 0.1814\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = np.exp(logits) / np.exp(logits).sum(-1, keepdims=True)\n",
    "    probs_class1 = probs[:, 1]\n",
    "    THRESHOLD = 0.4\n",
    "    preds = (probs_class1 >= threshold).astype(int)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds, average=\"binary\"), # Of all samples predicted as class 1, how many were actually 1?\n",
    "        \"recall\": recall_score(labels, preds, average=\"binary\"), # Of all actual class 1 samples, how many did the model correctly predict?\n",
    "        \"f1\": f1_score(labels, preds, average=\"binary\"),\n",
    "        \"auc\": roc_auc_score(labels, probs_class1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up TrainingArguments and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/disk/nobackup2/ipykernel_3521507/3851428372.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./training/output/llama-classifier\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    bf16=True,  # Use mixed-precision training to reduce memory usage\n",
    "    gradient_accumulation_steps=4,  # simulates a larger batch size without needing more memory\n",
    "    dataloader_num_workers=4,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-4,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./training/logs\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"recall\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized_dataset,\n",
    "    eval_dataset=eval_tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/speed-scratch/a_s87063/repos/perf-pilot/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='679' max='2202' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 679/2202 1:04:22 < 2:24:49, 0.18 it/s, Epoch 0.62/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../LLMs/finetuned/classification/model/llama3-8B\")\n",
    "tokenizer.save_pretrained(\"../LLMs/finetuned/classification/tokenizer/llama3-8B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(eval_tokenized_dataset)\n",
    "logits = predictions.predictions\n",
    "probs = np.exp(logits) / np.exp(logits).sum(-1, keepdims=True)\n",
    "\n",
    "print(\"Probabilities for class 1:\", probs[:, 1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
